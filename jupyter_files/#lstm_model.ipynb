{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from emotion_detection.loader import create_data_loader, split_data\n",
    "from emotion_detection.models import TextClassificationParsBert, pytorch_model\n",
    "\n",
    "from transformers import BertConfig, BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "max_len = 128\n",
    "train_batch_size = 128\n",
    "valid_batch_size = 128\n",
    "test_batch_size = 128\n",
    "\n",
    "epoch = 3\n",
    "EEVERY_EPOCH = 1000\n",
    "lr = 2e-5\n",
    "CLIP = 0.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  dataset process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import Stemmer, word_tokenize, Normalizer\n",
    "data = pd.read_csv('/mnt/disk2/arshia.yousefinezhad/emotion_detection/data/preprocess_labelencoding_data.csv')\n",
    "\n",
    "def preprocess_text(df):\n",
    "    def process_text(text):\n",
    "      text = re.sub(r'[^ا-ی!\\s]', '', text)\n",
    "      text = re.sub('[0-9]','',text)\n",
    "    \n",
    "      stemmer = Stemmer()\n",
    "      text_tokens = word_tokenize(text)\n",
    "      texts_clean = [stemmer.stem(word) for word in text_tokens]\n",
    "      text = \" \".join(texts_clean)\n",
    "      return text\n",
    "    df.combined_text = df.combined_text.apply(process_text)\n",
    "    return df\n",
    "\n",
    "data_prepared = preprocess_text(data)\n",
    "data_prepared[\"tokens\"] = data_prepared.combined_text.map(lambda text: text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset to train test validation\n",
    "call_data, data_val = train_test_split(data,test_size=0.15,  random_state=42 , stratify=data.emotion)\n",
    "data_train, data_test = train_test_split(call_data,test_size=0.1 ,  random_state=42 , stratify=call_data.emotion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = list(sorted(data_prepared['emotion'].unique()))\n",
    "\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {v: k for k, v in label2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum vocab numbers:  30517\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "from collections import defaultdict\n",
    "\n",
    "MAX_VOCAB = 30_000\n",
    "token_freq = defaultdict(int)\n",
    "\n",
    "for example in data_train.tokens:\n",
    "    for token in example:\n",
    "        token_freq[token] += 1\n",
    "\n",
    "print('maximum vocab numbers: ', max(list(token_freq.values())))\n",
    "\n",
    "token_freq = {key: value for key, value in token_freq.items() if value >= 3}\n",
    "\n",
    "sorted_tokens = ['<pad>', '<unk>'] + sorted(token_freq.keys(), key=lambda token: token_freq[token], reverse=True)[:MAX_VOCAB - 2]\n",
    "\n",
    "token2id = {token: idx for idx, token in enumerate(sorted_tokens)}\n",
    "id2token = {idx: token for token, idx in token2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class TextClassificationLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, num_classes):\n",
    "        super(TextClassificationLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        output = self.fc(lstm_out.view(len(sentence), -1))\n",
    "        return F.log_softmax(output, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(token2id) + 1\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "output_dim = len(label_list)\n",
    "\n",
    "model = TextClassificationLSTM(embedding_dim, hidden_dim, vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "  return [token2id.get(token, token2id['<unk>']) for token in example]\n",
    "\n",
    "data_train['tokens_ids'] = data_train.tokens.apply(tokenize_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id['عصبانی']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8890</th>\n",
       "      <td>عصبانی</td>\n",
       "      <td>نمیدون چرا باید اینقد عصاب خورد داشته_با تو خی...</td>\n",
       "      <td>[نمیدون, چرا, باید, اینقد, عصاب, خورد, داشته_ب...</td>\n",
       "      <td>[124, 27, 32, 550, 2615, 234, 807, 6, 12, 258,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10203</th>\n",
       "      <td>معمولی</td>\n",
       "      <td>خاله دیگه باشگاه نمیر نه یک ماهه نرف چراخوب می...</td>\n",
       "      <td>[خاله, دیگه, باشگاه, نمیر, نه, یک, ماهه, نرف, ...</td>\n",
       "      <td>[591, 14, 678, 642, 17, 28, 1189, 1152, 8086, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10186</th>\n",
       "      <td>معمولی</td>\n",
       "      <td>از برنامه ه بگو کدو برنامه برنامه دیگه حالا که...</td>\n",
       "      <td>[از, برنامه, ه, بگو, کدو, برنامه, برنامه, دیگه...</td>\n",
       "      <td>[7, 371, 16, 131, 321, 371, 371, 14, 44, 4, 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9060</th>\n",
       "      <td>غمگین و مضطرب</td>\n",
       "      <td>به هرچ خواس گف ناراح نبا نمیتون خیل ناراح باید...</td>\n",
       "      <td>[به, هرچ, خواس, گف, ناراح, نبا, نمیتون, خیل, ن...</td>\n",
       "      <td>[3, 620, 367, 74, 211, 310, 191, 12, 211, 32, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>عصبانی</td>\n",
       "      <td>صد بار به نگف وقت تو ماشین میشین درارو قفل کن ...</td>\n",
       "      <td>[صد, بار, به, نگف, وقت, تو, ماشین, میشین, درار...</td>\n",
       "      <td>[488, 185, 3, 564, 136, 6, 171, 944, 8087, 170...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>معمولی</td>\n",
       "      <td>زن تو چرا اینقدر میر پ رمال و دعا نویس میگ شای...</td>\n",
       "      <td>[زن, تو, چرا, اینقدر, میر, پ, رمال, و, دعا, نو...</td>\n",
       "      <td>[242, 6, 27, 209, 118, 92, 12552, 5, 590, 1347...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272</th>\n",
       "      <td>معمولی</td>\n",
       "      <td>تازه بیدار شد نه خیل وقته همیشه همین موقعا بید...</td>\n",
       "      <td>[تازه, بیدار, شد, نه, خیل, وقته, همیشه, همین, ...</td>\n",
       "      <td>[305, 379, 42, 17, 12, 621, 115, 88, 2344, 379...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9509</th>\n",
       "      <td>معمولی</td>\n",
       "      <td>دا یه تحقیق ارایه میداد راجب رنگ  واسه دانشگ ن...</td>\n",
       "      <td>[دا, یه, تحقیق, ارایه, میداد, راجب, رنگ, واسه,...</td>\n",
       "      <td>[117, 23, 1622, 11782, 905, 965, 369, 127, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>معمولی</td>\n",
       "      <td>میشه بگ شما دو نفر چرا مدا با ه بحث م کنین چون...</td>\n",
       "      <td>[میشه, بگ, شما, دو, نفر, چرا, مدا, با, ه, بحث,...</td>\n",
       "      <td>[36, 99, 39, 93, 286, 27, 633, 13, 16, 778, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5403</th>\n",
       "      <td>معمولی</td>\n",
       "      <td>ما تو کار پول نریخت هنوز چرا پسر پریشب بر کار ...</td>\n",
       "      <td>[ما, تو, کار, پول, نریخت, هنوز, چرا, پسر, پریش...</td>\n",
       "      <td>[49, 6, 21, 147, 7172, 178, 27, 182, 7789, 26,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8789 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             emotion                                      combined_text  \\\n",
       "8890          عصبانی  نمیدون چرا باید اینقد عصاب خورد داشته_با تو خی...   \n",
       "10203         معمولی  خاله دیگه باشگاه نمیر نه یک ماهه نرف چراخوب می...   \n",
       "10186         معمولی  از برنامه ه بگو کدو برنامه برنامه دیگه حالا که...   \n",
       "9060   غمگین و مضطرب  به هرچ خواس گف ناراح نبا نمیتون خیل ناراح باید...   \n",
       "1663          عصبانی  صد بار به نگف وقت تو ماشین میشین درارو قفل کن ...   \n",
       "...              ...                                                ...   \n",
       "3484          معمولی  زن تو چرا اینقدر میر پ رمال و دعا نویس میگ شای...   \n",
       "10272         معمولی  تازه بیدار شد نه خیل وقته همیشه همین موقعا بید...   \n",
       "9509          معمولی  دا یه تحقیق ارایه میداد راجب رنگ  واسه دانشگ ن...   \n",
       "4254          معمولی  میشه بگ شما دو نفر چرا مدا با ه بحث م کنین چون...   \n",
       "5403          معمولی  ما تو کار پول نریخت هنوز چرا پسر پریشب بر کار ...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "8890   [نمیدون, چرا, باید, اینقد, عصاب, خورد, داشته_ب...   \n",
       "10203  [خاله, دیگه, باشگاه, نمیر, نه, یک, ماهه, نرف, ...   \n",
       "10186  [از, برنامه, ه, بگو, کدو, برنامه, برنامه, دیگه...   \n",
       "9060   [به, هرچ, خواس, گف, ناراح, نبا, نمیتون, خیل, ن...   \n",
       "1663   [صد, بار, به, نگف, وقت, تو, ماشین, میشین, درار...   \n",
       "...                                                  ...   \n",
       "3484   [زن, تو, چرا, اینقدر, میر, پ, رمال, و, دعا, نو...   \n",
       "10272  [تازه, بیدار, شد, نه, خیل, وقته, همیشه, همین, ...   \n",
       "9509   [دا, یه, تحقیق, ارایه, میداد, راجب, رنگ, واسه,...   \n",
       "4254   [میشه, بگ, شما, دو, نفر, چرا, مدا, با, ه, بحث,...   \n",
       "5403   [ما, تو, کار, پول, نریخت, هنوز, چرا, پسر, پریش...   \n",
       "\n",
       "                                              tokens_ids  \n",
       "8890   [124, 27, 32, 550, 2615, 234, 807, 6, 12, 258,...  \n",
       "10203  [591, 14, 678, 642, 17, 28, 1189, 1152, 8086, ...  \n",
       "10186  [7, 371, 16, 131, 321, 371, 371, 14, 44, 4, 15...  \n",
       "9060   [3, 620, 367, 74, 211, 310, 191, 12, 211, 32, ...  \n",
       "1663   [488, 185, 3, 564, 136, 6, 171, 944, 8087, 170...  \n",
       "...                                                  ...  \n",
       "3484   [242, 6, 27, 209, 118, 92, 12552, 5, 590, 1347...  \n",
       "10272  [305, 379, 42, 17, 12, 621, 115, 88, 2344, 379...  \n",
       "9509   [117, 23, 1622, 11782, 905, 965, 369, 127, 1, ...  \n",
       "4254   [36, 99, 39, 93, 286, 27, 633, 13, 16, 778, 11...  \n",
       "5403   [49, 6, 21, 147, 7172, 178, 27, 182, 7789, 26,...  \n",
       "\n",
       "[8789 rows x 4 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list, offsets = [], [], [0]\n",
    "    for _, _row in batch.iterrows():\n",
    "        label_list.append(_row.emotion)\n",
    "        processed_text = torch.tensor(_row.tokens_ids, dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        offsets.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label2id[_row.emotion], dtype=torch.int64)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    text_list = torch.cat(text_list)\n",
    "    return label_list.to(device), text_list.to(device), offsets.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "train_loader = DataLoader(data_train, batch_size=64, collate_fn=collate_batch, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/mnt/disk2/miniconda3/envs/emotion_detection/lib/python3.11/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[215], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/disk2/miniconda3/envs/emotion_detection/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/mnt/disk2/miniconda3/envs/emotion_detection/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/mnt/disk2/miniconda3/envs/emotion_detection/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/disk2/miniconda3/envs/emotion_detection/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/mnt/disk2/miniconda3/envs/emotion_detection/lib/python3.11/site-packages/pandas/core/frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/mnt/disk2/miniconda3/envs/emotion_detection/lib/python3.11/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[212], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m emotion_labels \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_train]\n\u001b[1;32m      4\u001b[0m max_lenght \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_train])\n",
      "Cell \u001b[0;32mIn[212], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m [\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_train]\n\u001b[1;32m      2\u001b[0m emotion_labels \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_train]\n\u001b[1;32m      4\u001b[0m max_lenght \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mlen\u001b[39m(item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memotion_labels\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_train])\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "token_ids = [item['token_ids'] for item in data_train]\n",
    "emotion_labels = [item['emotion'] for item in data_train]\n",
    "\n",
    "max_lenght =  max([len(item['emotion_labels']) for item in data_train])\n",
    "\n",
    "padded_token_ids = [ids + [0] * (max_lenght - len(ids)) for ids in token_ids]\n",
    "padded_emotion_labels = [ids + [-1] * (max_lenght - len(ids)) for ids in emotion_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' عاشقانه و خوشحال', 'عصبانی', 'غمگین و مضطرب', 'معمولی', 'هیجانی و متعجب']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "train_loader = DataLoader(train_data, batch_size=64, collate_fn=collate_fn, drop_last=True)\n",
    "dev_loader = DataLoader(dev_ds, batch_size=64, collate_fn=collate_fn, drop_last=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64, collate_fn=collate_fn, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(train['combined_text'].to_numpy(), train['emotion'].to_numpy(), tokenizer, max_len, train_batch_size, label_list)\n",
    "valid_data_loader = create_data_loader(valid['combined_text'].to_numpy(), valid['emotion'].to_numpy(), tokenizer, max_len, valid_batch_size, label_list)\n",
    "test_data_loader = create_data_loader(test['combined_text'].to_numpy(), test['emotion'].to_numpy(), tokenizer, max_len, test_batch_size, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextClassificationLSTM(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParsBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [01:12<00:00,  1.00it/s]s]\n",
      "100%|██████████| 9/9 [00:03<00:00,  2.29it/s]\n",
      "Epochs... : 100%|██████████| 1/1 [01:16<00:00, 76.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "| end of epoch   1 | time: 76.62s | valid accuracy    0.644 \n",
      "-----------------------------------------------------------\n",
      "Checking the results of test dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:04<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy    0.644\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "torch_model = pytorch_model(model, criterion, optimizer, scheduler)\n",
    "torch_model.trainer(train_data_loader, valid_data_loader, test_data_loader, epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "این هست یک حالت معمولی \n"
     ]
    }
   ],
   "source": [
    "text = \"خیلی کیفت کوکه! چی شده؟,آره ، آزمون رانندگیمو قبول شدم \\\n",
    "اولین بار بود؟,نه بابا 5 بار رد شده بودم \\\n",
    "پس باید بهم شیرینی بدی,چشم، اینقد خوشحالم که میتونم یه شهرو شیرینی بدم \\\n",
    "حالا نمیخواد ولخرجی کنی ، شکم مارو سیر کنی کافیه,بزن  بریم تجریش یه ناهار مشتی بهت بدم \\\n",
    "بابا شرمنده میکنی,بیا بریم امروز فقط عشق و حاله\"\n",
    "\n",
    "model_torch_model = torch_model.model\n",
    "\n",
    "model = model.to(\"cpu\")\n",
    "\n",
    "print(\"این هست یک حالت %s \" % id2label[torch_model.predict(text, tokenizer)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emotion_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
